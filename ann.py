# -*- coding: utf-8 -*-
"""second

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ro-CzOZkOoZIVU9vAN4JZYeCO1venTzn
"""

from keras.layers.regularization.dropout import Dropout

import pandas as pd
import numpy as np


import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import seaborn as sn
from scikeras.wrappers import KerasClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

pip install scikeras

from google.colab import drive
drive.mount('/content/drive')

#file path
path = '/content/drive/MyDrive/research_data/TrainingUpdated.csv'
#read csv file
df = pd.read_csv(path, on_bad_lines='skip',low_memory=False)
#check info
# print(df.head())
# df.info()
# drop rows with nan
df.dropna()

#encode prognosis 
encoder = LabelEncoder()
df["prognosis"] = encoder.fit_transform(df["prognosis"])
df = df.sample(frac=1).reset_index(drop=True)
#Y
Y = df['prognosis']
y = np_utils.to_categorical(Y)
#X 
X =df.drop(['prognosis'], axis=1)
X = np.array(X)
print(X.shape)
print(Y.shape)

# model 1
#  model = Sequential()
#  model.add(Dense(64, input_shape=(142,), activation='relu'))
#  model.add(Dense(50, activation='softmax'))
#  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
#  model.summary()

#  model 2
#  model = Sequential()
#  model.add(Dense(60, input_shape=(142,), activation='relu'))
#  model.add(Dropout(0.5))
#  model.add(Dense(50, activation='softmax'))
#  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
#  model.summary()

# model 3
#  model = Sequential()
#  model.add(Dense(142, input_shape=(142,), activation='relu'))
#  model.add(Dropout(0.5))
#  model.add(Dense(71, activation='relu'))
#  model.add(Dropout(0.5))
#  model.add(Dense(50, activation='softmax'))
#  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
#  model.summary()

#  # model 4
#  model = Sequential()
#  model.add(Dense(71, input_shape=(142,), activation='relu'))
#  model.add(Dense(35, activation='relu'))
#  model.add(Dense(50, activation='softmax'))
#  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
#  model.summary()

history = model.fit(X,y,epochs=100,batch_size=256,shuffle=True,validation_split=0.2,verbose=2)

acc = history.history['accuracy']
 val_acc = history.history['val_accuracy']
 # loss
 loss = history.history['loss']
 val_loss = history.history['val_loss']

 # range of X (no. of epochs)
 epochs = range(1, len(acc) + 1)

 # plot
 plt.plot(epochs, acc, 'r', label='Training accuracy')
 plt.plot(epochs, val_acc, 'g', label='Validation accuracy')
 plt.title('Training and validation accuracy')
 plt.xlabel('Epochs')
 plt.ylabel('Accuracy')
 plt.legend()
 plt.show()

val = [0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
newX = np.asarray([val])
prediction = np.argmax(model.predict(newX), axis=1)
print(prediction[0])
print(encoder.inverse_transform(prediction))

from keras.utils import plot_model
plot_model(model)

from tensorflow.keras.models import save_model

import pickle

pickle.dump(model, open('model.pkl', 'wb'))

pip freeze > requirements.txt